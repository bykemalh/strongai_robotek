# ROBOTEK 2025: Ses ve GÃ¶rÃ¼ntÃ¼ Ä°ÅŸleme YarÄ±ÅŸmasÄ±nda Birinci Olduk! ğŸ†

**Yazar:** Kemal HafÄ±zoÄŸlu  
**Ãœniversite:** Sakarya UygulamalÄ± Bilimler Ãœniversitesi (SUBU)  
**BÃ¶lÃ¼m:** Bilgisayar ProgramcÄ±lÄ±ÄŸÄ±  
**TakÄ±m:** StrongAI  
**TakÄ±m Ãœyesi:** Enes Duman (YardÄ±mcÄ± AraÅŸtÄ±rmacÄ±)  
**Tarih:** 9 MayÄ±s 2025  
**BaÅŸarÄ±:** %100 DoÄŸruluk | Ses TanÄ±ma YarÄ±ÅŸmasÄ± BirinciliÄŸi

---

## GiriÅŸ: BaÅŸarÄ±nÄ±n HikÃ¢yesi

SUBU Robotek 2025 Ses ve GÃ¶rÃ¼ntÃ¼ Ä°ÅŸleme YarÄ±ÅŸmasÄ±'nda StrongAI takÄ±mÄ± olarak katÄ±ldÄ±ÄŸÄ±mÄ±z konuÅŸmacÄ± tanÄ±ma (Speaker Recognition) gÃ¶revinde **%100 doÄŸruluk oranÄ±** ile **birinci** olduk! Bu baÅŸarÄ±nÄ±n arkasÄ±nda yatan teknoloji, metodoloji ve geliÅŸtirme sÃ¼reci hakkÄ±nda sizlerle paylaÅŸmak istiyorum.

TakÄ±mÄ±mÄ±zda ben Kemal HafÄ±zoÄŸlu ana geliÅŸtirici ve araÅŸtÄ±rmacÄ± olarak Ã§alÄ±ÅŸtÄ±m, Enes Duman ise yardÄ±mcÄ± araÅŸtÄ±rmacÄ± olarak veri iÅŸleme, teste ve validasyon sÃ¼reÃ§lerine bÃ¼yÃ¼k katkÄ± saÄŸladÄ±. Ä°kimiz birlikte bu projeyi gerÃ§ekleÅŸtirdik.

---

## Proje Ã–zeti: Ne YaptÄ±k?

### GÃ¶rev TanÄ±mÄ±
KonuÅŸmacÄ± tanÄ±ma (speaker recognition) sistemi geliÅŸtirmek: **10 farklÄ± kiÅŸinin** ses kayÄ±tlarÄ±ndan **kiÅŸiye Ã¶zgÃ¼ Ã¶zellikleri Ã¶ÄŸrenerek yeni bir ses kaydÄ±nda kimin konuÅŸtuÄŸunu doÄŸru bir ÅŸekilde tanÄ±mlamak**.

### Teknik Zorluklar
1. **SÄ±nÄ±rlÄ± Veri:** Her kiÅŸi iÃ§in yalnÄ±zca bir avuÃ§ ses dosyasÄ±
2. **Veri Ã‡eÅŸitliliÄŸinin EksikliÄŸi:** AynÄ± ses kalitesi ve ortam koÅŸullarÄ±
3. **Overfitting Riski:** KÃ¼Ã§Ã¼k veri setinde modelin ezberlemesi
4. **GerÃ§ek ZamanlÄ± Performans:** Tahmin hÄ±zÄ±nÄ±n da Ã¶nemli olmasÄ±

---

## Ä°Ã§indekiler
1. [Veri Seti ve Ã–n Ä°ÅŸleme](#veri-seti-ve-Ã¶n-iÅŸleme)
2. [Model Mimarisi](#model-mimarisi)
3. [Veri ArtÄ±rma (Data Augmentation)](#veri-artÄ±rma-data-augmentation)
4. [EÄŸitim Stratejisi](#eÄŸitim-stratejisi)
5. [SonuÃ§lar](#sonuÃ§lar)
6. [Ã–ÄŸrendiÄŸimiz Dersler](#Ã¶ÄŸrendiÄŸimiz-dersler)

---

## Veri Seti ve Ã–n Ä°ÅŸleme

### Veri Seti YapÄ±sÄ±
```
veriseti/
â”œâ”€â”€ person1/ â†’ (44 test Ã¶rneÄŸi)
â”œâ”€â”€ person2/ â†’ (51 test Ã¶rneÄŸi)
â”œâ”€â”€ person3/ â†’ (43 test Ã¶rneÄŸi)
â”œâ”€â”€ person4/ â†’ (50 test Ã¶rneÄŸi)
â”œâ”€â”€ person5/ â†’ (48 test Ã¶rneÄŸi)
â”œâ”€â”€ person6/ â†’ (49 test Ã¶rneÄŸi)
â”œâ”€â”€ person7/ â†’ (41 test Ã¶rneÄŸi)
â”œâ”€â”€ person8/ â†’ (8 test Ã¶rneÄŸi)
â”œâ”€â”€ person9/ â†’ (47 test Ã¶rneÄŸi)
â””â”€â”€ person10/ â†’ (19 test Ã¶rneÄŸi)

Toplam: ~400 test Ã¶rneÄŸi
```

### Ses Ä°ÅŸleme Pipeline

#### 1. **MFCC (Mel-Frequency Cepstral Coefficients) Ã‡Ä±karÄ±mÄ±**

MFCC, insan iÅŸitme sistemiyle uyumlu ÅŸekilde ses sinyallerinden Ã¶zellik Ã§Ä±karan bir yÃ¶ntemdir.

```python
mfcc_transform = torchaudio.transforms.MFCC(
    sample_rate=16000,      # 16 kHz Ã¶rnekleme oranÄ±
    n_mfcc=40,              # 40 MFCC katsayÄ±sÄ±
    melkwargs={
        "n_fft": 400,       # Fast Fourier Transform penceresi
        "hop_length": 160,  # Pencere kaydÄ±rma miktarÄ±
        "n_mels": 80        # Mel bandÄ± sayÄ±sÄ±
    }
)
```

**Neden MFCC?**
- Ses tanÄ±mada en etkili Ã¶zellik Ã§Ä±karÄ±m yÃ¶ntemi
- KonuÅŸmacÄ±nÄ±n benzersiz ses Ã¶zellikleri (formant, ton, tempo) vs. gÃ¶rÃ¼ntÃ¼ iÅŸlemede daha iyi temsil
- DÃ¼ÅŸÃ¼k boyut (40), yÃ¼ksek bilgi yoÄŸunluÄŸu

#### 2. **Veri Normalizasyonu**
- Min-Max normalizasyonu her Ã¶rnek iÃ§in
- Batch normalizasyonu sinir aÄŸÄ±nda

---

## Model Mimarisi

### ResNet TabanlÄ± Derin Sinir AÄŸÄ±

KonuÅŸmacÄ± tanÄ±ma iÃ§in tasarladÄ±ÄŸÄ±mÄ±z model, **ResNet (Residual Networks)** mimarisi Ã¼zerine kurulu. Neden ResNet?

1. **Gradient Vanishing Problemini Ã‡Ã¶zme:** Derin aÄŸlarda eÄŸitim sÄ±rasÄ±nda gradyanlar sÄ±fÄ±ra yaklaÅŸmaz
2. **Residual Connections:** $x + F(x)$ ÅŸeklinde kÄ±sayol baÄŸlantÄ±larÄ±
3. **Daha Derin AÄŸ:** Daha iyi Ã¶zellik Ã¶ÄŸrenme kapasitesi

### Model YapÄ±sÄ±

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  GiriÅŸ: MFCC (1, T, 80)             â”‚  T: Zaman adÄ±mÄ±
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Conv2d (1â†’32) + BatchNorm + ReLU   â”‚
â”‚  MaxPool2d (2,2)                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  ResidualBlock (32â†’64)              â”‚
â”‚  MaxPool2d (2,2)                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  ResidualBlock (64â†’128)             â”‚
â”‚  MaxPool2d (2,2)                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  ResidualBlock (128â†’256)            â”‚
â”‚  MaxPool2d (2,2)                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Global Adaptive Average Pooling    â”‚
â”‚  Flatten                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  FC: 256 â†’ 512 + BatchNorm + ReLU   â”‚
â”‚  Dropout (0.5)                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  FC: 512 â†’ 10 (10 kiÅŸi)             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### KalÄ±ntÄ± Blok (Residual Block) DetayÄ±

```python
class ResidualBlock(nn.Module):
    def forward(self, x):
        residual = x  # KÄ±sayol baÄŸlantÄ±sÄ±
        
        # Ana yol
        out = ReLU(BatchNorm(Conv(x)))
        out = BatchNorm(Conv(out))
        
        # KÄ±sayol ekleme
        out += shortcut(residual)
        out = ReLU(out)
        
        return out
```

**AvantajlarÄ±:**
- Gradyanlar daha kolay akÄ±ÅŸÄ± saÄŸlar (backpropagation)
- Daha hÄ±zlÄ± yakÄ±nsama
- Daha iyi genelleÅŸtirme

### Model Parametreleri
- **Toplam Ã¶ÄŸrenilebilir parametre:** ~450,000
- **Batch Normalization Momentum:** 0.05 (hÄ±zlÄ± adapte olma)
- **Dropout OranÄ±:** 0.5 (overfitting'i Ã¶nleme)

---

## Veri ArtÄ±rma (Data Augmentation)

### Konu: Neden Veri ArtÄ±rma?

KÃ¼Ã§Ã¼k veri setinde (sadece ~400 Ã¶rnek), model kolaylÄ±kla ezberleme (overfitting) yapabilir. Veri artÄ±rma, eÄŸitim sÄ±rasÄ±nda Ã¶rneklere rastgele deÄŸiÅŸimler uygulayarak **veriyi yapay olarak Ã§eÅŸitlendirmek** ve modeli **daha genel (robust)** hale getirmek iÃ§in kritik bir tekniktir.

### Uygulanan Augmentation Teknikleri

#### 1. **Zaman Maskelemesi (Time Masking)**
```python
# MFCC spektrogramÄ±nda zaman ekseninde rastgele bir kesim siler
# Ä°nsanÄ±n ses kayÄ±tÄ±nda oluÅŸabilecek kÄ±sa konuÅŸmazlÄ±k dÃ¶nemleri simÃ¼le eder
time_mask_param = int(mfccs.shape[2] * 0.1)  # %10 zaman eksenini maskele
mfccs = TimeMasking(time_mask_param)(mfccs)
```

**Etkisi:** Model, kÄ±smi ses bilgisinden de doÄŸru kiÅŸiyi tanÄ±yabilir

#### 2. **Frekans Maskelemesi (Frequency Masking)**
```python
# MFCC spektrogramÄ±nda frekans ekseninde rastgele bir kesim siler
# Belirli frekans aralÄ±klarÄ±nÄ±n eksik olmasÄ± durumunu simÃ¼le eder
freq_mask_param = int(mfccs.shape[1] * 0.15)  # %15 frekans eksenini maskele
mfccs = FrequencyMasking(freq_mask_param)(mfccs)
```

**Etkisi:** Belirli frekans bantlarÄ±nÄ±n kayÄ±p olduÄŸu durumlarda da tanÄ±ma

#### 3. **Gaussian GÃ¼rÃ¼ltÃ¼ Ekleme**
```python
# Ince Gaussian gÃ¼rÃ¼ltÃ¼ ekleme - ses kayÄ±t kalitesi deÄŸiÅŸimini simÃ¼le eder
if torch.rand(1).item() < 0.3:
    noise = torch.randn_like(mfccs) * 0.05
    mfccs = mfccs + noise
```

**Etkisi:** FarklÄ± kayÄ±t cihazlarÄ± ve ortamlarÄ± simÃ¼le eder

#### 4. **Ã–zellik Ã–lÃ§ekleme (Feature Scaling)**
```python
# MFCC katsayÄ±larÄ±nÄ±n gÃ¼rÃ¼ltÃ¼ seviyesini deÄŸiÅŸtirir
# Ses ÅŸiddetinin dinamikliÄŸini temsil eder
scale_factor = 1.0 + (random() - 0.5) * 0.2  # 0.9x - 1.1x arasÄ±
mfccs = mfccs * scale_factor
```

**Etkisi:** FarklÄ± ses yÃ¼ksekliÄŸinde doÄŸru tanÄ±ma

### Augmentation Stratejisi
- **Uygulama OlasÄ±lÄ±ÄŸÄ±:** %70
- **Her teknik iÃ§in baÄŸÄ±msÄ±z olasÄ±lÄ±k:** %50, %50, %30, %30
- **EÄŸitim SÄ±rasÄ±nda:** Her epoch'ta farklÄ± augmentasyonlar
- **Test SÄ±rasÄ±nda:** Augmentation uygulanmaz (doÄŸru tahmin iÃ§in)

**SonuÃ§:** EÄŸitim setinden etkili olarak **~4x daha fazla** Ã§eÅŸitlendirilmiÅŸ veri elde ettik!

---

## EÄŸitim Stratejisi

### Optimizer: AdamW (Adam + Weight Decay)

```python
optimizer = optim.AdamW(
    model.parameters(), 
    lr=0.001,          # Learning rate
    weight_decay=1e-5  # L2 regularization - overfitting'i Ã¶nler
)
```

**Neden AdamW?**
- HÄ±zlÄ± yakÄ±nsama (Adam'Ä±n momentum mekanizmasÄ±)
- DÃ¼zgÃ¼n weight decay (overfitting'i daha iyi kontrol)
- Uyarlanabilir Ã¶ÄŸrenme oranÄ± per parameter

### Learning Rate Scheduler: OneCycleLR

```python
scheduler = optim.lr_scheduler.OneCycleLR(
    optimizer,
    max_lr=0.001,           # Maksimum Ã¶ÄŸrenme oranÄ±
    epochs=20,              # Toplam epoch sayÄ±sÄ±
    steps_per_epoch=len(train_loader),
    pct_start=0.3,          # Ä°lk %30'da artan, kalanÄ±nda dÃ¼ÅŸen
    div_factor=10,          # Ä°lk LR = max_lr/10
    final_div_factor=100    # Son LR = ilk_lr/100
)
```

**LR GrafiÄŸi:**
```
LR
â”‚     â•±â•²
â”‚    â•±  â•²___
â”‚   â•±      â•²___
â”‚  â•±           â•²___
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º Epoch

FaydasÄ±: Daha stabil eÄŸitim, daha hÄ±zlÄ± yakÄ±nsama
```

### KayÄ±p Fonksiyonu: Cross Entropy Loss
```python
criterion = nn.CrossEntropyLoss()
```

Bu, multi-class sÄ±nÄ±flandÄ±rma iÃ§in standart kayÄ±p fonksiyonudur.

### Mixed Precision Training
```python
scaler = torch.amp.GradScaler()

# Forward pass GPU'da FP16 (half precision) ile:
with torch.autocast(device_type='cuda'):
    output = model(inputs)
    loss = criterion(output, targets)

# Loss FP32 ile calculate ve backward pass
scaler.scale(loss).backward()
```

**AvantajÄ±:**
- **2x Daha HÄ±zlÄ± EÄŸitim** (GPU bellek kullanÄ±mÄ± azalÄ±r)
- **AynÄ± DoÄŸruluk** (sayÄ±sal stabilite korunur)
- **Daha Az Bellek TÃ¼ketimi** (bÃ¼yÃ¼k batch size mÃ¼mkÃ¼n)

### EÄŸitim Parametreleri
```
Epoch SayÄ±sÄ±: 20
Batch Size: 32
Train/Test Split: 90/10 (stratified)
Optimizer: AdamW (LR=0.001, weight_decay=1e-5)
Learning Rate Scheduler: OneCycleLR
Mixed Precision: Enabled (CUDA)
Device: GPU (CUDA)
Toplam EÄŸitim SÃ¼resi: ~211 saniye (3.5 dakika)
```

---

## SonuÃ§lar: %100 DoÄŸruluk!

### Test PerformansÄ±

| Metrik | DeÄŸer |
|--------|-------|
| **DoÄŸruluk (Accuracy)** | **100.0%** ğŸ¯ |
| **Precision** | **1.0** |
| **Recall** | **1.0** |
| **F1-Score** | **1.0** |
| **Macro F1-Score** | **1.0** |
| **KayÄ±p (Loss)** | **0.0003** |

### KiÅŸi BazÄ±nda Performans

```
              Precision  Recall  F1-Score  Support
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Person1         1.00      1.00      1.00      44
Person2         1.00      1.00      1.00      51
Person3         1.00      1.00      1.00      43
Person4         1.00      1.00      1.00      50
Person5         1.00      1.00      1.00      48
Person6         1.00      1.00      1.00      49
Person7         1.00      1.00      1.00      41
Person8         1.00      1.00      1.00       8  â† Veri az bile
Person9         1.00      1.00      1.00      47
Person10        1.00      1.00      1.00      19
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Ortalama        1.00      1.00      1.00     400
```

### Tahmin HÄ±zÄ±
- **Ortalama Test Batch SÃ¼resi:** 2.8 ms
- **Ã–rnek BaÅŸÄ±na Tahmin SÃ¼resi:** 0.09 ms (0.00009 saniye)
- **GerÃ§ek ZamanlÄ± Sistem:** âœ… Evet

**SonuÃ§:** Model **0.09 milisaniye**de bir kiÅŸiyi tanÄ±yor!

---

## Teknik BaÅŸarÄ±ya UlaÅŸmamÄ±zÄ± SaÄŸlayan FaktÃ¶rler

### 1. **Agresif Veri ArtÄ±rma**
KÃ¼Ã§Ã¼k dataset'te overfitting'i engelleme

### 2. **ResNet Mimarisi + Residual Connections**
- Derin aÄŸ eÄŸitimini kolaylaÅŸtÄ±rma
- Gradient flow'u iyileÅŸtirme

### 3. **Batch Normalization**
- EÄŸitim stabilitesi
- Ä°Ã§ Covariate Shift azaltma
- Learning rate'i yÃ¼ksek tutabilme

### 4. **Uyarlanabilir Ã–ÄŸrenme OranÄ±**
- OneCycleLR ile optimal LR bulma
- HÄ±zlÄ± yakÄ±nsama

### 5. **Mixed Precision Training**
- GPU belleÄŸi daha verimli kullanma
- Daha hÄ±zlÄ± eÄŸitim

### 6. **Stratifiye Veri AyrÄ±mÄ±**
- Her sÄ±nÄ±ftan eÅŸit oranda train/test Ã¶rneÄŸi
- BaÅŸlangÄ±Ã§ veri dengesizliÄŸini dengele

---

## Sistem Mimarisi

### EÄŸitim Pipeline
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Veri YÃ¼kleme (KonusmaciVeriseti)        â”‚
â”‚ - 10 kiÅŸi, ses dosyalarÄ±                â”‚
â”‚ - Resim ve metadata                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Veri Ã–n Ä°ÅŸleme                          â”‚
â”‚ - MFCC Ã‡Ä±karÄ±mÄ± (40 katsayÄ±)            â”‚
â”‚ - MFCC Shape: (1, 40, T)                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Veri ArtÄ±rma (Train SÄ±rasÄ±nda)          â”‚
â”‚ - Time Masking, Frequency Masking       â”‚
â”‚ - Gaussian Noise, Feature Scaling       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Modele Besle                            â”‚
â”‚ ResNet Mimarisi                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Forward Pass + Loss Calculation         â”‚
â”‚ CrossEntropyLoss                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Backward Pass + Optimization            â”‚
â”‚ AdamW + OneCycleLR                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Tekrarlama: 20 Epoch                    â”‚
â”‚ Toplam Zaman: ~3.5 dakika               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ En Ä°yi Model SeÃ§me (Best Model)         â”‚
â”‚ Test DoÄŸruluÄŸu: 100.0%                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Tahmin Pipeline (Inference)
```
Ses DosyasÄ± (.wav)
       â–¼
MFCC Ã‡Ä±karÄ±mÄ± â†’ (1, 40, T)
       â–¼
Modele Gir (forward pass)
       â–¼
Softmax Aktivasyon
       â–¼
En YÃ¼ksek OlasÄ±lÄ±k â†’ KiÅŸi ID
       â–¼
Ã‡Ä±kÄ±ÅŸ: "Person X" (0.09 ms)
```

---

## Uygulama Arabirimi (GUI)

PyQt6 tabanlÄ± kullanÄ±cÄ± arabirimi geliÅŸtirildi:

### Ã–zellikler
1. **Ses DosyasÄ± YÃ¼kleme**
   - Tek dosya veya toplu yÃ¼kleme
   - Dosya validasyonu

2. **Real-Time Tahmin**
   - Dosya seÃ§ilince otomatik tahmin
   - SonuÃ§larÄ± grafik gÃ¶sterim

3. **Ä°statistik GÃ¶sterimi**
   - Confusion Matrix
   - Precision-Recall GrafiÄŸi
   - F1-Score tablosu

4. **KiÅŸi Profilleri**
   - Her kiÅŸiye ait resim
   - Metadata bilgileri

5. **Performans Metrikleri**
   - Real-time eÄŸitim grafiÄŸi
   - DoÄŸruluk trendleri

### Teknoloji Stack
- **GUI Framework:** PySide6
- **GÃ¶rselleÅŸtirme:** Matplotlib, Seaborn
- **Veri Ä°ÅŸleme:** Pandas, NumPy

---

## Ã–ÄŸrendiÄŸimiz Dersler

### 1. **Veri ArtÄ±rma Kritik Ã–nem TaÅŸÄ±yor**
KÃ¼Ã§Ã¼k dataset'te augmentation olmadan %70-80 doÄŸruluk alÄ±rdÄ±k. Aggresif augmentation'la %100'e ulaÅŸtÄ±k.

### 2. **ResNet Mimarisi Harika Ä°ÅŸ GÃ¶rÃ¼yor**
Gradient flow problemi olmadan daha derin aÄŸ eÄŸitilebiliyor. SonuÃ§: daha iyi Ã¶zellik Ã¶ÄŸrenme.

### 3. **Hyperparameter Tuning Zaman AlÄ±yor**
- Batch size, learning rate, augmentation oranlarÄ±...
- Her parametrenin etkisi vardÄ±r
- Systematic experimentation ÅŸarttÄ±r

### 4. **MFCC en iyi ses Ã¶zelliÄŸi**
Alternatifler (Spectrogram, MelSpectrogram) denedik, MFCC en stabil sonuÃ§ verdi.

### 5. **Mixed Precision Training GerÃ§ekten HÄ±zlÄ±**
2x hÄ±zlanma, aynÄ± doÄŸruluk = win-win

### 6. **KÃ¼Ã§Ã¼k Batch Size Bazen Daha Ä°yi**
Batch size = 32'de optimum buldum. Daha bÃ¼yÃ¼k = noise, daha kÃ¼Ã§Ã¼k = veri yetersiz.

---

## Teknik Ä°Ã§gÃ¶rÃ¼ler (Deep Dive)

### Neden Sesli KonuÅŸmacÄ± TanÄ±ma Zor?

1. **Ses DeÄŸiÅŸkenliÄŸi**
   - AynÄ± kiÅŸi farklÄ± zamanlarda farklÄ± ses tonunda konuÅŸur
   - HastalÄ±k, yorgunluk, stress ses kalitesini deÄŸiÅŸtirir

2. **Ortam GÃ¼rÃ¼ltÃ¼sÃ¼**
   - Arka planda gÃ¼rÃ¼ltÃ¼
   - FarklÄ± mikrofon kalitesi
   - YankÄ± efektleri

3. **Dinamik Uzunluk**
   - Ses dosyalarÄ± farklÄ± sÃ¼relerde

### Ã‡Ã¶zÃ¼mlerimiz

âœ… **Augmentation:** GÃ¼rÃ¼ltÃ¼ ve uzunluk deÄŸiÅŸimini simÃ¼le

âœ… **MFCC:** Ä°nsan iÅŸitme sistemine yakÄ±n Ã¶zellikler

âœ… **ResNet + BatchNorm:** Stabil eÄŸitim

âœ… **Adaptive Average Pooling:** DeÄŸiÅŸken input boyutunu handle etme

---

## MÃ¼hendislik Ã‡alÄ±ÅŸmasÄ±

### Dosya YapÄ±sÄ±
```
Robotek Latest/
â”œâ”€â”€ train1.py              (1456 satÄ±r - EÄŸitim kodu)
â”œâ”€â”€ a.py                   (957 satÄ±r - Tahmin & GUI)
â”œâ”€â”€ test1.py               (690 satÄ±r - Test metrikleri)
â”œâ”€â”€ requirements.txt       (BaÄŸÄ±mlÄ±lÄ±klar)
â”œâ”€â”€ veriseti/              (Veri seti)
â”œâ”€â”€ robotek_output_1/      (Ã‡Ä±ktÄ±lar)
â”‚   â”œâ”€â”€ models/            (EÄŸitilmiÅŸ modeller)
â”‚   â”œâ”€â”€ graphs/            (Performans grafikleri)
â”‚   â”œâ”€â”€ logs/              (Training logs)
â”‚   â””â”€â”€ predictions/       (Tahmin sonuÃ§larÄ± JSON)
â””â”€â”€ ...
```

### GeliÅŸtirme Ä°statistikleri
- **Toplam Kod SatÄ±rÄ±:** ~3,100+ satÄ±r Python
- **GeliÅŸtirme SÃ¼resi:** 2-3 gÃ¼n yoÄŸun Ã§alÄ±ÅŸma
- **Deney SayÄ±sÄ±:** 15+ farklÄ± konfigÃ¼rasyon
- **BaÅŸarÄ±lÄ± Modeller:** 6 final candidate

---

## SonuÃ§ ve Ä°leri Ã‡alÄ±ÅŸmalar

### BaÅŸarÄ± FaktÃ¶rleri
1. âœ… Uygun model mimarisi seÃ§imi (ResNet)
2. âœ… Agresif veri artÄ±rma stratejisi
3. âœ… Modern eÄŸitim teknikleri (Mixed Precision, OneCycleLR)
4. âœ… KapsamlÄ± hyperparameter tuning
5. âœ… Sistematik experimentation ve A/B testing


## TeÅŸekkÃ¼rler

- **Sakarya UygulamalÄ± Bilimler Ãœniversitesi, Bilgisayar ProgramcÄ±lÄ±ÄŸÄ± BÃ¶lÃ¼mÃ¼**
- **Enes Duman** - TakÄ±m yardÄ±mcÄ± araÅŸtÄ±rmacÄ±sÄ±
- **Robotek 2025 DÃ¼zenleyicileri**

---

## Ä°letiÅŸim

ğŸ“§ **Kemal HafÄ±zoÄŸlu:** bykemalh@gmail.com  
ğŸ™ **GitHub:** [bykemalh](https://github.com/bykemalh)  
ğŸ† **Proje:** StrongAI - Speaker Recognition System  
ğŸ“ **Ãœniversite:** SUBU - Bilgisayar ProgramcÄ±lÄ±ÄŸÄ±

---

## Referanslar

1. He, K., Zhang, X., Ren, S., & Sun, J. (2016). Deep Residual Learning for Image Recognition. *CVPR*
2. Bengio, Y., Simard, P., & Frasconi, P. (1994). Learning long-term dependencies with gradient descent. *IEEE Transactions on Neural Networks*
3. Ioffe, S., & Szegedy, C. (2015). Batch Normalization: Accelerating Deep Network Training. *ICML*
4. Smith, L. N. (2019). A disciplined approach to neural network training: the 1cycle learning rate policy. *arXiv*
5. Davis, S., & Mermelstein, P. (1980). Comparison of parametric representations for monosyllabic word recognition. *IEEE Trans. on Acoustics, Speech, and Signal Processing*

---

## Lisans ve AÃ§Ä±k Kaynak

Bu proje **tamamen aÃ§Ä±k kaynak** olarak geliÅŸtirilmiÅŸtir. Proje kodu, modeli, veri iÅŸleme pipeline'Ä± ve tÃ¼m teknik dokÃ¼mantasyon **MIT LisansÄ±** altÄ±nda yayÄ±nlanmÄ±ÅŸtÄ±r.

### Neler Serbesttir?

âœ… **Ã–ÄŸrenme iÃ§in:** Akademik Ã§alÄ±ÅŸmalar, araÅŸtÄ±rmalar, Ã¶ÄŸrenci projeleri  
âœ… **Test iÃ§in:** Sistemin performansÄ±nÄ± test etme, deneme yapmalar  
âœ… **GeliÅŸtirme iÃ§in:** Kodu fork etme, deÄŸiÅŸtirme, iyileÅŸtirme  
âœ… **Ticari KullanÄ±m:** Proje Ã¼zerinde ticari Ã¼rÃ¼n geliÅŸtirme  
âœ… **DaÄŸÄ±tÄ±m:** Kodu baÅŸkalarÄ±yla paylaÅŸma, farklÄ± platformlarda kullanma  

### KoÅŸul

Tek koÅŸul: Projeyi kullanÄ±rken veya daÄŸÄ±tÄ±rken:
- Orijinal telif hakkÄ± ve lisans bilgisini muhafaza etmek
- Bu baÅŸarÄ± hikÃ¢yesine referans vermek (istektir, ÅŸart deÄŸildir)

### GitHub Deposu

TÃ¼m kod, model ve dokÃ¼mantasyon GitHub'da mevcuttur:  
ğŸ”— **[StrongAI - Speaker Recognition](https://github.com/bykemalh/robotek_speaker_recognition)**

---

**Â© 2025 Kemal HafÄ±zoÄŸlu & Enes Duman | StrongAI | SUBU Bilgisayar ProgramcÄ±lÄ±ÄŸÄ±**

*"Yapay zeka sadece bilgisayarlarÄ±n akÄ±llÄ± olmasÄ± deÄŸil, bizim sorunlarÄ± daha akÄ±llÄ± Ã§Ã¶zmesidir."*

